---
title: "IRT-M Vignette"
author: "Margaret Foster"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{IRT-M Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

In this document we narratively walk through use of the IRT-M package.  Although the IRT-M framework is case agnostic, here we focus on a single use case in which a hypothetical research team is interested in seeking empirical support for the hypothesis that anti-immigration attitudes in Europe are associated with perceptions of cultural, economic, and security threats. This example illustrates one of the strengths of the IRT-M model; namely the (very common) situation in which researchers have a theoretical question and related data that does not directly address the substantive question of interest. In this case, we work through a research question derived from the literature on European attitudes towards immigration. The threat response hypothesis is supported by the literature~\cite{kentmen2017anti} but  was not a specific focus of the 2020-2021 Eurobarometer wave. Consequentially, the survey did not directly as questions about the three threat dimensions of interest.  However, the survey contained several questions adjacent to threat perception.  We can use these questions to build an M-Matrix and estimate latent threat dimensions.

Regardless of the use case, there are three steps to  preparing data for the IRT-M Package:

+ First, create a key for how you expect your theory to interact with the data. 
+ Next, format the data so that it can be parsed by the sampler. 
+ Third, create anchor points for the resulting scale.

## Formatting the Observed Data

Formatting the Data

IRT-M requires converting categorical variables into a numeric format with one response loaded into each input object (aka: question). The most straightforward way to do this is to use a library, such as `fastDummies` to expand the entire instrument into one-hot or binary encoding. This is also a good opportunity to export an empty data-frame with the list of question codes, to code the M-Code object. Doing so reduces the likelihood of formatting slippages that are tedious to fix.  We have also found it to be worthwhile to insert column with human-readable notes next to the question codes. This step adds some overhead, but--- much like commenting code in general--- is invaluable for debugging and analysis.

## Creating the M-Matrix

The core step  in using the IRT-M package is to map the underlying theoretical constructions of interest into an 'M-Matrix' of dimension loadings. In order to develop the loadings, we go through every question on the "test" object (here: every question in the survey) and decide whether the question relates to one of our hypothesized theoretical dimensions. For those questions that we believe load on the theoretical dimension of interest, we can code whether we expect it to positively load---meaning that an affirmative response implies more of the dimension--- or negatively load. We code positive "loading" as $1$ in the M-Matrix, negative "loading" as $-1$. We can also denote that the question has no relationship with the theoretical dimension of interest, in which case we code 0 into the dimension. If we are unsure, not coding the loading inserts $NA$ value, and the model will learn any loading during the estimation step.


To begin, we reformat data so that each possible answer becomes a separate binary question (One Hot encoding). In preparing the data, we used the `dummy_cols()` utility from the `fastdummies` package.  Finally, we rename the new binary dataframe as `Y` to underscore that this is the observed data that we will be modeling  

```{r, eval=F, echo=T}
library(tidyverse)
library(stats)
dataPath <- "./Data/"
ebdat <- read_csv(paste0(dataPath,
                         "SI395.csv"))
ebdatsub <- ebdat[,c(58:413)]

## Convert numeric ordinal responses to factors
library(fastDummies)
ebdatsub <- lapply(ebdatsub[,], factor)
ebbinary <- dummy_cols(.data=ebdatsub,
                       remove_selected_columns=TRUE)
Y <- ebbinary ## data
```

In this case, we are interested whether respondents to the 2021 Eurobarometer reported feeling social, cultural, and/or economic threats. Depending on the data, you may need to do some additional processing at this step to ensure that each question coded is a binary response has a single relationship to each dimension being coded. Many surveys present questions formatted into feelings thermometers, matrices, or with many nested sub-questions. These may not load straightforwardly into a single dimension. For example, Question 377 (qa1.4) in our data asks for respondents' feelings about various current situations, compactly presented via a feeling thermometer for several sub-questions. In this example we will code the fourth, “How would you judge the current situation in [….] your personal job situation.” The respondent’s answer is coded as categorical variable ranging from 1-4, with a response of 1 corresponding to “Very Good” and 4 corresponding to “Very Bad.”  We imagine that this question directly relates to the “economic threat” underlying dimension that we hypothesize, with the negative end of the scale indicating feelings of economic threat and a negative answer suggesting no threat.

Thus, we expand the levels of the question prompt to become four separate yes/no questions:

+ qa1a_4_1. Situation of personal job: very good. 
+ qa1a_4_2 Situation of personal job: rather good
+ qa1a_4_3 Situation of personal job: rather bad
+ qa1a_4_4. Situation of personal job: very bad  

Now we can use these prompts to code for our theoretical loading. In the M-Code matrix, we add a 1 to the column for the Economic Threat dimension for qa1a_4_3 and qa1a_4_4. Substantively, this means that responses to the qa1.4 with a value in the data of “3” or “4" are coded as individual respondents who likely score high on the “economic threat” dimension.  We can also code the inverse and give qa1a_4_1 and qa1a_4_2 the value of -1 on the M-Code matrix because we expect that Eurobarometer respondents who answer that they feel that their personal job situation is “very good” or “rather good” likely do not score highly on economic threat. 

We repeat this process for each of the questions that we think relate (both positively and negatively) to our underlying theoretical frames and, if the outcome that we are interested in comes from the data, for questions that relate to the DV. This step is admittedly time consuming, but it is what allows us to make theoretical claims about the results. Fortunately we only need to code questions that are related to our underlying dimensions of interests.  

Here we also highlight the ability of the IRT-M model to handle inductive theoretical exploration as well. As we coded the M-Matrix for the three dimensions of threat featured in our literature review, observed that the survey itself featured a number of questions about feelings of threat related to the ongoing Covid-19 pandemic. IRT-M easily supports inductive coding, and we added another dimension for the emergent category of "health threat."

We thus end up with a `K x D` matrix, where `K` is the number of theoretically-salient binarized questions and `D` is the total number of underlying dimensions and number of outcomes in the data being coded.  The columns consist of the question codes, potentially a human-readable comment, and then a series of `{-1, 0, 1}` codes for whether the question relates to the dimension or outcome of interest.

Fortunately, `K`, the number of binary questions to be hand coded, is likely to be substantially smaller than the overall number of dummy variables because we only need to code those questions that relate to the theory/outcome. We can ignore the rest, which will go into the model code as a 0. Finally, we if we want the model to impute unknown answers (such as did not answer/did not ask results) we can enter those into the `M-Code` matrix as “NA” and have the model impute values.

For convenience, we processed the codes in a separate spreadsheet, which we import into the script. We also reduce the M-Matrix to include only rows with loading information.
```{r, eval=F, echo=T}

MCodes <- read_csv(paste0(dataPath,
                           "Immigration_EB_MCodes.csv"))

## Only keep M-Codes with loadings or outcomes:
MCodes$encoding <- rowSums(abs(MCodes[,4:9])) 
MCodes <- MCodes[which(MCodes$encoding > 0),]
```

## Processing with IRT-M

Once we have the data and M-Matrix identified (and have cleaned column names for consistency between M-Matrix and response data), we combine the data and M Matrix. We merge and the data and loadings, resulting in a `K x R` matrix where `K` is the number of binary questions that we have codes for and R are the number of instrument responses.  This is accomplished by the following code snippet:

```{r, eval=F, echo=T}
## Produce a K-coded questions x R-responses data frame:
combine <- MCodes[,c(2, 4:9)] %>% ## question codes and loadings 
    inner_join(
        Y %>% 
        t() %>% 
        as.data.frame(stringsAsFactors = FALSE) %>% 
        type_convert() %>%
        rownames_to_column(var = "question"),
        by = c("QMap" = "question"  )
    ) 
```

Next we create the `M-Matrix` by instantiating a `K x d x d` array of matrices. As above, `K` is the number of coded loading questions, and `d` is the number of coded dimensions. 

Finally, we rebuild the outcome data by ensuring that we have coded (or NA) M matricies for each question that remains in our data. At the end, we have two data structures for our analysis: the `M-Matrix` which is a list of diagonal matrices of dimension `d x d x K` coding loadings. The second object is a dataframe, `Y`, that has dimension `R` responses x `K` questions with coded (and `NA`) loadings.
These are the objects that `IRT-M` will use for the estimation

The M-Code data structure becomes our model’s “M-Matrix” (M) object. 
The conversion produces a `dxd` matrix for each question that is 0 everywhere except for the diagonal, which is a 1 if that question loads on the dimension.


```{r, eval=F, echo=T}
d <- 6 #number of coded dimensions
loadings <- 2:7 ## columns in combine object with the loadings

M <- array(NA, c(d, d, nrow(combine)))
for (i in 1:nrow(combine)) {
    M[,,i] <- diag(combine[i,
                           loadings])
}
```

We also create the final `Y` object for the IRTM estimator to use. Namely, we reverse the transposition of the `Y` dataframe and ensure that we have question names that are consistently formatted for the constraint matricies and the observed data. Finally, we save the `Y` and `M` object. Troubleshooting note: it is important that the `Y` object is numeric. You can check the data types by running Dplyr’s `summary(response_object)` [or similar] and adjust the data type if needed.
```{r, eval=F, echo=T}
#Reverse the earlier transposition of the observations:
Y <- combine[, (d+2):ncol(combine)]%>%
    t() %>%
    as.data.frame()

Y <- as.data.frame(sapply(Y, as.numeric))


## Take the question names and 
## convert to column names

question <- combine[,1] %>%
    as.data.frame() 
colnames(Y) <- question[,1]

## Save M and Y for the sampler
saveRDS(M,
        file=paste0(dataPath,
                    "EB_M.rds"))

saveRDS(Y,
        file=paste0(dataPath,
                    "EB_Y.rds"))
```


## Anchors

Adding synthetic anchor points is mathematically optional for the purposes of identifying the model. However, it is substantively helpful to provide a clear substantive interpretation and consistent scale of the underlying space. The anchor points create artificial extreme points scales the endpoints and fixes the directions of the loadings. The function `pair_gen_anchors()`  generates these anchor points, taking the list of `M matrice`s and an integer value for the scale. The value of the integer is not important so long as it is positive-- it simply sets the length of the scale. `pair_gen_anchors()` returns a set of artificial respondents that anchor each of the extremes of our dimensions. 

We finalize the anchors object by calling `anchors()` which takes the pairs generated by `pair_gen_anchors()` and the `Y` observed values object.  We also create two objects to help us keep track of the introduced anchor points: `d_which_fix` and `d_theta_fix`. These record the index points of the synthetic extreme points that were created in `anchors()` and `pair_gen_anchors()`

```{r, eval=F, echo=T}
l2 <- pair_gen_anchors(M,5)
l3 <- anchors(l2, Y) 
d_which_fix <- 1:nrow(l3$Yfake)
d_theta_fix <- l2$theta_fake 
```

##Running IRT-M

Once we have the `M`, `Y`, and `anchors` objects we can input them into the IRT-M sampler. The sampler takes as additional parameters the number of dimensions (`d`), the identification of which points are the synthetic anchors, and parameters for desired burn-in and sampling iterations. We input these into `M_constrained_irt()`, which will return a list with the estimated `Theta`, `Lambda`, `b`, `Sigma`, and `Omega` values. `

The `Theta` object gives us the estimated distribution of the theoretical quantities of interest. This object is a responses x dimensions x number of simulations list. Substantively, this gives us a respondent-level estimate of their distribution over each of the theoretical dimensions. In order to derive population-level distributions of the quantity of interest, we will need to first reduce the dimensions. For simplicity, here we take the mean, using `apply(irt$theta, c(1,2), mean)` to produce an object that is the number of respondents x a number of dimensions: what we are looking for!. 

The `Omega` object provides a covariance matrix for latent loadings, while the `Sigma` object is a covariance matrix for the latent factors. The `Lambda` object produces estimates of how each question loads on the underlying dimensions. The `b` output object is the baseline discrimination parameter for each item, and captures how well each item differentiates between the dimensions.

In this example, our anchors object is `l3` , where `l3$Yall` is a matrix that contains both the anchor points as well as our actual observed data. By default, anchors() places the anchor points first in the matrix. It is not necessary that the anchor points are first as long as you note where they are, because we will want to remove them for the analysis.

```{r, eval=F, echo=T}
d=6
nsamp= 10^3
nburn=20^1

irt <- M_constrained_irt(l3$Yall,
            d = d,
            M= abs(M)*2,
            theta_fix = d_theta_fix,
            which_fix = d_which_fix,
            nburn=nburn,
            nsamp=nsamp,
            thin=1,
            learn_Omega=TRUE)

```

The `IRT-M` sampler can also run in an unconstrained mode without the coded M-Matrix or the fixed anchor points. This can be a useful in a number of circumstances, most notably if the analyst wants to evaluate the impact of their coding decisions. Running an unconstrained IRT model is straightforward: we simply do not provide the sampler with an M-Matrix or anchor points. The preparation of the observed data (the Y data object) is the same. As before, the Y object is a matrix of N responses by Q questions and d is the number of underlying dimensions that the model is seeking.

The code below will run the sampler on the formatted data (burn-in and sampler runtime for example; a real runtime would be closer to 10^3- 10^34 iterations with a 2,000 burn-in).


```{r, eval=F, echo=T}
d=6
irt.unconstrained <- M_constrained_irt(Y=Y,
            d=d,
            nburn=100, 
            nsamp=100,
            thin=1,
            learn_Omega=TRUE)
```

Note that the `Rfortran` dependency requires `gcc` to be installed on mac. Some machines running Mac OS encounter a well-known problem with R finding `gfortran`. The steps for solving this are documented online, and typically entail a combination of installing `Xcode`, using `homebrew` to install `gcc`, and/or installing `gfortran` directly from `Github`. 

## Interpretation and Analysis

Once we run the IRT-M sampler, we presumably want to 

One thing that we might want to do after estimating posterior distributions for our thetas of interest is to bring in additional variables from the data into our analysis. The IRT-M code itself does not keep unique ids for responses, however it retains the order of the data. This allows us to attach variables that we might want after deriving the `Theta` estimates.

### Visualizations:
Walk through some visualization options, based on the Eurobarometer codebase

### Lambda
[*Todo: here develop some code to interpret Lambda]-- based on the Afrobarometer code

